{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRGAN.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"e_qKb9EvA60Z"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NokihrxLSlnT"},"source":["cd /content/drive/MyDrive/Colab Notebooks/ADL/2/SRGAN_pytorch/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPONp2JgLcGj"},"source":["pip install torch==1.4.0 torchvision==0.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"URUhIB0Nccw3"},"source":["#Install Packages"]},{"cell_type":"code","metadata":{"id":"MgczXaWIcdSK"},"source":["from os import listdir\r\n","from os.path import join\r\n","from PIL import Image\r\n","import torch\r\n","from torch import nn\r\n","from torchvision.models.vgg import vgg16\r\n","from torch.utils.data.dataset import Dataset\r\n","from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\r\n","import math\r\n","from math import log10\r\n","import pandas as pd\r\n","import torch.optim as optim\r\n","import torch.utils.data\r\n","import torchvision.utils as utils\r\n","from torch.autograd import Variable\r\n","from torch.utils.data import DataLoader\r\n","from tqdm import tqdm\r\n","import pytorch_ssim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Iz4YiIaWzGO"},"source":["#Definations"]},{"cell_type":"code","metadata":{"id":"W9TJj1cUWwVs","executionInfo":{"status":"ok","timestamp":1609218599209,"user_tz":-330,"elapsed":1660,"user":{"displayName":"dhaval parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd3Jo3svniyovfhBYEQ1VWz0vebW7WscZEmKG6=s64","userId":"10750883927593226872"}}},"source":["def is_image_file(filename):\r\n","    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\r\n","\r\n","\r\n","def calculate_valid_crop_size(crop_size, upscale_factor):\r\n","    return crop_size - (crop_size % upscale_factor)\r\n","\r\n","\r\n","def train_hr_transform(crop_size):\r\n","    return Compose([\r\n","        RandomCrop(crop_size),\r\n","        ToTensor(),\r\n","    ])\r\n","\r\n","\r\n","def train_lr_transform(crop_size, upscale_factor):\r\n","    return Compose([\r\n","        ToPILImage(),\r\n","        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\r\n","        ToTensor()\r\n","    ])\r\n","\r\n","\r\n","\r\n","class TrainDatasetFromFolder(Dataset):\r\n","    def __init__(self, dataset_dir, crop_size, upscale_factor):\r\n","        super(TrainDatasetFromFolder, self).__init__()\r\n","        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\r\n","        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\r\n","        self.hr_transform = train_hr_transform(crop_size)\r\n","        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\r\n","\r\n","    def __getitem__(self, index):\r\n","        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\r\n","        lr_image = self.lr_transform(hr_image)\r\n","        return lr_image, hr_image\r\n","\r\n","    def __len__(self):\r\n","        return len(self.image_filenames)\r\n","\r\n","\r\n","class ValDatasetFromFolder(Dataset):\r\n","    def __init__(self, dataset_dir, upscale_factor):\r\n","        super(ValDatasetFromFolder, self).__init__()\r\n","        self.upscale_factor = upscale_factor\r\n","        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\r\n","\r\n","    def __getitem__(self, index):\r\n","        hr_image = Image.open(self.image_filenames[index])\r\n","        w, h = hr_image.size\r\n","        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\r\n","        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\r\n","        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\r\n","        hr_image = CenterCrop(crop_size)(hr_image)\r\n","        lr_image = lr_scale(hr_image)\r\n","        hr_restore_img = hr_scale(lr_image)\r\n","        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\r\n","\r\n","    def __len__(self):\r\n","        return len(self.image_filenames)\r\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xcZV7ysWm-y","executionInfo":{"status":"ok","timestamp":1609218602032,"user_tz":-330,"elapsed":1239,"user":{"displayName":"dhaval parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd3Jo3svniyovfhBYEQ1VWz0vebW7WscZEmKG6=s64","userId":"10750883927593226872"}}},"source":["class Generator(nn.Module):\r\n","    def __init__(self, scale_factor):\r\n","        upsample_block_num = int(math.log(scale_factor, 2))\r\n","\r\n","        super(Generator, self).__init__()\r\n","        self.block1 = nn.Sequential(\r\n","            nn.Conv2d(3, 64, kernel_size=9, padding=4),\r\n","            nn.PReLU()\r\n","        )\r\n","        self.block2 = ResidualBlock(64)\r\n","        self.block3 = ResidualBlock(64)\r\n","        self.block4 = ResidualBlock(64)\r\n","        self.block5 = ResidualBlock(64)\r\n","        self.block6 = ResidualBlock(64)\r\n","        self.block7 = ResidualBlock(64)\r\n","        self.block8 = ResidualBlock(64)\r\n","        self.block9 = ResidualBlock(64)\r\n","        self.block10 = ResidualBlock(64)\r\n","        self.block11 = ResidualBlock(64)\r\n","        self.block12 = ResidualBlock(64)\r\n","        self.block13 = ResidualBlock(64)\r\n","        self.block14 = ResidualBlock(64)\r\n","        self.block15 = ResidualBlock(64)\r\n","        self.block16 = ResidualBlock(64)\r\n","        self.block17 = ResidualBlock(64)\r\n","        self.block18 = nn.Sequential(\r\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\r\n","            nn.BatchNorm2d(64)\r\n","        )\r\n","        block19 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\r\n","        block19.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\r\n","        self.block19 = nn.Sequential(*block19)\r\n","\r\n","    def forward(self, x):\r\n","        block1 = self.block1(x)\r\n","        block2 = self.block2(block1)\r\n","        block3 = self.block3(block2)\r\n","        block4 = self.block4(block3)\r\n","        block5 = self.block5(block4)\r\n","        block6 = self.block6(block5)\r\n","        block7 = self.block7(block6)\r\n","        block8 = self.block8(block7)\r\n","        block9 = self.block9(block8)\r\n","        block10 = self.block10(block9)\r\n","        block11 = self.block11(block10)\r\n","        block12 = self.block12(block11)\r\n","        block13 = self.block13(block12)\r\n","        block14 = self.block14(block13)\r\n","        block15 = self.block15(block14)\r\n","        block16 = self.block16(block15)\r\n","        block17 = self.block17(block16)\r\n","        block18 = self.block18(block17)\r\n","\r\n","        block19 = self.block19(block1 + block18)\r\n","\r\n","        return (torch.tanh(block19) + 1) / 2\r\n","\r\n","\r\n","class Discriminator(nn.Module):\r\n","    def __init__(self):\r\n","        super(Discriminator, self).__init__()\r\n","        self.net = nn.Sequential(\r\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\r\n","            nn.BatchNorm2d(64),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\r\n","            nn.BatchNorm2d(128),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\r\n","            nn.BatchNorm2d(128),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\r\n","            nn.BatchNorm2d(256),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\r\n","            nn.BatchNorm2d(256),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\r\n","            nn.BatchNorm2d(512),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\r\n","            nn.BatchNorm2d(512),\r\n","            nn.LeakyReLU(0.2),\r\n","\r\n","            nn.AdaptiveAvgPool2d(1),\r\n","            nn.Conv2d(512, 1024, kernel_size=1),\r\n","            nn.LeakyReLU(0.2),\r\n","            nn.Flatten(),\r\n","            nn.Linear(1024,512),\r\n","            nn.LeakyReLU(0.2),\r\n","            nn.Linear(512,1)\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        batch_size = x.size(0)\r\n","        return torch.sigmoid(self.net(x).view(batch_size))\r\n","\r\n","\r\n","class ResidualBlock(nn.Module):\r\n","    def __init__(self, channels):\r\n","        super(ResidualBlock, self).__init__()\r\n","        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\r\n","        self.bn1 = nn.BatchNorm2d(channels)\r\n","        self.prelu = nn.PReLU()\r\n","        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\r\n","        self.bn2 = nn.BatchNorm2d(channels)\r\n","\r\n","    def forward(self, x):\r\n","        residual = self.conv1(x)\r\n","        residual = self.bn1(residual)\r\n","        residual = self.prelu(residual)\r\n","        residual = self.conv2(residual)\r\n","        residual = self.bn2(residual)\r\n","\r\n","        return x + residual\r\n","\r\n","\r\n","class UpsampleBLock(nn.Module):\r\n","    def __init__(self, in_channels, up_scale):\r\n","        super(UpsampleBLock, self).__init__()\r\n","        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\r\n","        self.pixel_shuffle = nn.PixelShuffle(up_scale)\r\n","        self.prelu = nn.PReLU()\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv(x)\r\n","        x = self.pixel_shuffle(x)\r\n","        x = self.prelu(x)\r\n","        return x\r\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVNTG3cokFwq"},"source":["class GeneratorLoss(nn.Module):\r\n","    def __init__(self):\r\n","        super(GeneratorLoss, self).__init__()\r\n","        vgg = vgg16(pretrained=True)\r\n","        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\r\n","        for param in loss_network.parameters():\r\n","            param.requires_grad = False\r\n","        self.loss_network = loss_network\r\n","        self.mse_loss = nn.MSELoss()\r\n","        self.tv_loss = TVLoss()\r\n","\r\n","    def forward(self, out_labels, out_images, target_images):\r\n","        # Adversarial Loss\r\n","        out_labels = torch.log(out_labels)\r\n","        adversarial_loss = torch.mean(- out_labels)\r\n","        # Perception Loss\r\n","        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\r\n","        # Image Loss\r\n","        image_loss = self.mse_loss(out_images, target_images)\r\n","        return image_loss + 0.001 * adversarial_loss + 0.06 * perception_loss\r\n","        # return image_loss  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fijgfGcF5nwa"},"source":["#SRNET"]},{"cell_type":"code","metadata":{"id":"xkwBbnzV5fpC"},"source":["CROP_SIZE = 96\r\n","UPSCALE_FACTOR = 4\r\n","NUM_EPOCHS = 1000\r\n","load_model=False\r\n","gen_path='Pretrained Generator model Path'\r\n","\r\n","train_set = TrainDatasetFromFolder('data/DIV2K_train_HR', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\r\n","train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\r\n","\r\n","netG = Generator(UPSCALE_FACTOR)\r\n","generator_criterion = GeneratorLoss()\r\n","\r\n","if torch.cuda.is_available():\r\n","    netG.cuda()\r\n","    generator_criterion.cuda()\r\n","\r\n","if load_model:\r\n","    netG.load_state_dict(torch.load(gen_path))\r\n","\r\n","optimizerG = optim.Adam(netG.parameters(),lr=0.0001)\r\n","\r\n","results = {'g_loss': []}\r\n","\r\n","for epoch in range(1, NUM_EPOCHS + 1):\r\n","    print(f'Epoch : {epoch}')\r\n","    train_bar = tqdm(train_loader)\r\n","    running_results = {'batch_sizes': 0, 'g_loss': 0}\r\n","\r\n","    netG.train()\r\n","    for data, target in train_bar:\r\n","        g_update_first = True\r\n","        batch_size = data.size(0)\r\n","        running_results['batch_sizes'] += batch_size\r\n","\r\n","        real_img = Variable(target)\r\n","        if torch.cuda.is_available():\r\n","            real_img = real_img.cuda()\r\n","        z = Variable(data)\r\n","        if torch.cuda.is_available():\r\n","            z = z.cuda()\r\n","        fake_img = netG(z)\r\n","\r\n","        #Update G network\r\n","        netG.zero_grad()\r\n","        g_loss = generator_criterion(fake_img, real_img)\r\n","        print(f'G Loss : {g_loss}')\r\n","        g_loss.backward()\r\n","        optimizerG.step()\r\n","\r\n","        running_results['g_loss'] += g_loss.item() * batch_size\r\n","\r\n","    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\r\n","\r\n","    if epoch %20 == 0 and epoch != 0:\r\n","        torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d_SRNet.pth' % (UPSCALE_FACTOR, epoch))\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eS8_jqoN51Jc"},"source":["#SRGAN"]},{"cell_type":"code","metadata":{"id":"K8Xv-qeO52x6"},"source":["CROP_SIZE = 96\r\n","UPSCALE_FACTOR = 4\r\n","NUM_EPOCHS = 1000\r\n","load_model=True\r\n","gen_path='Pretrained Generator model Path'\r\n","dec_path='Pretrained Discriminator model Path'\r\n","\r\n","train_set = TrainDatasetFromFolder('data/DIV2K_train_HR', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\r\n","train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\r\n","\r\n","netG = Generator(UPSCALE_FACTOR)\r\n","netD = Discriminator()\r\n","\r\n","generator_criterion = GeneratorLoss()\r\n","\r\n","if torch.cuda.is_available():\r\n","    netG.cuda()\r\n","    netD.cuda()\r\n","    generator_criterion.cuda()\r\n","\r\n","if oad_model:\r\n","    print('Loading previous model')\r\n","    netG.load_state_dict(torch.load(gen_path))\r\n","    # netD.load_state_dict(torch.load(dis_path))\r\n","\r\n","optimizerG = optim.Adam(netG.parameters(),lr=0.0001)\r\n","optimizerD = optim.Adam(netD.parameters(),lr=0.00001)\r\n","\r\n","results = {'d_loss': [], 'g_loss': [], 'r_score': [], 'f_score': []}\r\n","\r\n","for epoch in range(1, NUM_EPOCHS + 1):\r\n","    print(f'Epoch : {epoch}')\r\n","    train_bar = tqdm(train_loader)\r\n","    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'r_score':0,'f_score':0}\r\n","\r\n","    netG.train()\r\n","    netD.train()\r\n","    for data, target in train_bar:\r\n","        g_update_first = True\r\n","        batch_size = data.size(0)\r\n","        running_results['batch_sizes'] += batch_size\r\n","\r\n","        real_img = Variable(target)\r\n","        if torch.cuda.is_available():\r\n","            real_img = real_img.cuda()\r\n","        z = Variable(data)\r\n","        if torch.cuda.is_available():\r\n","            z = z.cuda()\r\n","        fake_img = netG(z)\r\n","        real_out = torch.log(netD(real_img)).mean()\r\n","        fake_dout = netD(fake_img)\r\n","        fake_out = torch.log(fake_dout).mean()\r\n","        d_loss = - real_out - fake_out\r\n","        #Update D network\r\n","        if epoch%5==0:\r\n","          netD.zero_grad()\r\n","          d_loss.backward(retain_graph=True)\r\n","          optimizerD.step()\r\n","\r\n","        #Update G network\r\n","        g_loss = generator_criterion(fake_dout, fake_img, real_img)\r\n","        # print(f'G Loss : {g_loss}')\r\n","        netG.zero_grad()\r\n","        g_loss.backward()\r\n","        optimizerG.step()\r\n","\r\n","        running_results['g_loss'] += g_loss.item() * batch_size\r\n","        running_results['d_loss'] += d_loss.item() * batch_size\r\n","        running_results['r_score'] += real_out.item() * batch_size\r\n","        running_results['f_score'] += fake_out.item() * batch_size\r\n","\r\n","        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\r\n","            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\r\n","            running_results['g_loss'] / running_results['batch_sizes'],\r\n","            running_results['r_score'] / running_results['batch_sizes'],\r\n","            running_results['f_score'] / running_results['batch_sizes']))\r\n","\r\n","    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\r\n","    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\r\n","    results['r_score'].append(running_results['r_score'] / running_results['batch_sizes'])\r\n","    results['f_score'].append(running_results['f_score'] / running_results['batch_sizes'])\r\n","\r\n","    if epoch %10 == 0 and epoch != 0:\r\n","        torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d_SRGAN.pth' % (UPSCALE_FACTOR, epoch))\r\n","        torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d_SRGAN.pth' % (UPSCALE_FACTOR, epoch))\r\n","        out_path = 'statistics/'\r\n","        data_frame = pd.DataFrame(\r\n","            data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_real': results['r_score'],\r\n","                  'Score_fake': results['f_score'] },index=range(1, (epoch + 1)))\r\n","        data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results_SRGAN.csv', index_label='Epoch')\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_adP78hRgu7"},"source":["#Convert LR to SR"]},{"cell_type":"code","metadata":{"id":"M1sxT_2CJmGy"},"source":["UPSCALE_FACTOR=4\r\n","netG = Generator(UPSCALE_FACTOR)\r\n","\r\n","if torch.cuda.is_available():\r\n","    netG.cuda()\r\n","\r\n","netG.load_state_dict(torch.load('Pretrained Generator model Path'))\r\n","\r\n","IMAGE_NAME='0863x4.png'\r\n","image=Image.open(IMAGE_NAME)\r\n","image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\r\n","\r\n","image = image.cuda()\r\n","\r\n","out = netG(image)\r\n","out_img = ToPILImage()(out[0].data.cpu())\r\n","out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_SRGAN_' + IMAGE_NAME)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eNSTYdgJRmlw"},"source":["#Compute PSNR and  SSIM for Validation set"]},{"cell_type":"code","metadata":{"id":"DdqDMbAdsHXG"},"source":["UPSCALE_FACTOR=4\r\n","netG = Generator(UPSCALE_FACTOR)\r\n","\r\n","if torch.cuda.is_available():\r\n","    netG.cuda()\r\n","\r\n","netG.load_state_dict(torch.load('Pretrained Generator model Path))\r\n","\r\n","netG.eval()\r\n","out_path = 'updatd_training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\r\n","\r\n","val_set = ValDatasetFromFolder('data/DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)\r\n","val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=False)\r\n","\r\n","with torch.no_grad():\r\n","    val_bar = tqdm(val_loader)\r\n","    valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\r\n","    val_images = []\r\n","    for val_lr, val_hr_restore, val_hr in val_bar:\r\n","        batch_size = val_lr.size(0)\r\n","        valing_results['batch_sizes'] += batch_size\r\n","        lr = val_lr\r\n","        hr = val_hr\r\n","        if torch.cuda.is_available():\r\n","            lr = lr.cuda()\r\n","            hr = hr.cuda()\r\n","        sr = netG(lr)\r\n","\r\n","        batch_mse = ((sr - hr) ** 2).data.mean()\r\n","        valing_results['mse'] += batch_mse * batch_size\r\n","        batch_ssim = pytorch_ssim.ssim(sr, hr).item()\r\n","        valing_results['ssims'] += batch_ssim * batch_size\r\n","        valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\r\n","        valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\r\n","        val_bar.set_description(desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\r\n","                valing_results['psnr'], valing_results['ssim']))\r\n"],"execution_count":null,"outputs":[]}]}